{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle, @epochs\n",
    "using Base.Iterators: repeated, partition\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "# load CIFAR-10 training set\n",
    "trainX, trainY = CIFAR10.traindata()\n",
    "testX,  testY  = CIFAR10.testdata()\n",
    "\n",
    "# MLDatasets returns UInt8 thus convert it to Float64\n",
    "trainX = Array{Float64}(trainX)\n",
    "testX = Array{Float64}(testX)\n",
    "println(\"conversion is done\")\n",
    "\n",
    "# construct one-hot vectors from labels\n",
    "trainY = onehotbatch(trainY, 0:9)\n",
    "testY = onehotbatch(testY, 0:9)\n",
    "\n",
    "train = (trainX, trainY)\n",
    "\n",
    "\n",
    "# TODO convert below to list comprehension\n",
    "# TODO shuffle\n",
    "# split training set into batches\n",
    "# train_data contains whole data in batches\n",
    "train_data = Array{Any}(div(50000, BATCH_SIZE))\n",
    "for i = 0:div(50000, BATCH_SIZE) - 1\n",
    "    train_data[i+1] = train[1][:,:,:, 1 + i*BATCH_SIZE:(i+1)*BATCH_SIZE],\n",
    "                      train[2][:, 1 + i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "end\n",
    "\n",
    "println(\"data is ready to be learnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  Conv((3,3), 3=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((2,2), 16=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(8*7*7 , 10), softmax)\n",
    "\n",
    "m(train_data[1][1])\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(argmax(m(x)) .== argmax(y))\n",
    "evalcb = throttle(() -> @show(accuracy(testX, testY)), 10)\n",
    "opt = ADAM(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to train\n",
    "\n",
    "# Flux.train!() runs for 1 epoch, default. \n",
    "# Change 15 to train for different epochs using @epochs macro\n",
    "@epochs 15 Flux.train!(loss, train, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
